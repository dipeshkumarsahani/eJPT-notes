
## ğŸ§  HTTP Apache Enumeration 

---

#### ğŸ” Step 1: Initial Reconnaissance

```bash
nmap <ip>
nmap -p 80 -sV --script banner <ip>
```

* `nmap <ip>` â€“ Scans all open ports.
* `-p 80` â€“ Focuses only on HTTP port.
* `-sV` â€“ Detects version.
* `--script banner` â€“ Retrieves service banners (can reveal server type, version etc.).

---

#### ğŸ› ï¸ Step 2: Metasploit Scanners

1. **HTTP Version Detection**

```bash
msfconsole
use auxiliary/scanner/http/http_version
set RHOSTS <ip>
run
```

2. **Brute Force Directory Enumeration**

```bash
use auxiliary/scanner/http/brute_dirs
set RHOSTS <ip>
run
```

3. **Robots.txt Discovery**

```bash
use auxiliary/scanner/http/robots_txt
set RHOSTS <ip>
run
```

---

#### ğŸŒ Step 3: Manual Enumeration via CLI

1. **CURL**

```bash
curl http://<ip> | more
```

2. **WGET**

```bash
wget http://<ip>/index
cat index | more
```

3. **BROWSH**

```bash
browsh --startup-url http://<ip>
```

4. **LYNX**

```bash
lynx http://<ip>
```

---

#### ğŸ› ï¸ Step 4: Directory Brute Forcing with `dirb`

```bash
dirb http://<ip> /usr/share/metasploit-framework/wordlists/directory.txt
```

* `dirb` brute forces directories using a wordlist.
* Helps discover hidden files, admin panels, backups, etc.

---

### âœ… Summary

| Tool          | Purpose                                  |
| ------------- | ---------------------------------------- |
| `nmap`        | Scan ports, banner grabbing              |
| `metasploit`  | HTTP version, robots.txt, brute dirs     |
| `curl`        | Retrieve page source via CLI             |
| `wget`        | Download files                           |
| `lynx/browsh` | Text-based browser (offline/CLI viewing) |
| `dirb`        | Directory brute-forcing with wordlist    |
